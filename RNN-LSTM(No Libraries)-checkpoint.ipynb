{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - LSTM without any Libraries.......\n",
    "![title](RNN-LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RecurrentNeuralNetwork:\n",
    "    \n",
    "    def __init__ (self, input, output, recurrences, expected_output, learning_rate):\n",
    "        #initial input \n",
    "        self.x = np.zeros(input)\n",
    "        #input size \n",
    "        self.input = input\n",
    "        #expected output \n",
    "        self.y = np.zeros(output)\n",
    "        #output size\n",
    "        self.output = output\n",
    "        #weight matrix \n",
    "        self.w = np.random.random((output, output))\n",
    "        #matrix used in RMSprop in order to decay the learning rate\n",
    "        self.G = np.zeros_like(self.w)\n",
    "        #length of the recurrent network\n",
    "        self.recurrences = recurrences\n",
    "        #learning rate \n",
    "        self.learning_rate = learning_rate\n",
    "        #array for storing inputs\n",
    "        self.ia = np.zeros((recurrences+1,input))\n",
    "        #array for storing cell states\n",
    "        self.ca = np.zeros((recurrences+1,output))\n",
    "        #array for storing outputs\n",
    "        self.oa = np.zeros((recurrences+1,output))\n",
    "        #array for storing hidden states\n",
    "        self.ha = np.zeros((recurrences+1,output))\n",
    "        #forget gate \n",
    "        self.af = np.zeros((recurrences+1,output))\n",
    "        #input gate\n",
    "        self.ai = np.zeros((recurrences+1,output))\n",
    "        #cell state\n",
    "        self.ac = np.zeros((recurrences+1,output))\n",
    "        #output gate\n",
    "        self.ao = np.zeros((recurrences+1,output))\n",
    "        #array of expected output values\n",
    "        self.expected_output = np.vstack((np.zeros(expected_output.shape[0]), expected_output.T))\n",
    "        #declare LSTM cell \n",
    "        self.LSTM = LSTM(input, output, recurrences, learning_rate)\n",
    "    \n",
    "    #sigmoid activation function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    #derivative of sigmoid \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))    \n",
    "    \n",
    "    #Forward Propagation\n",
    "    def forwardProp(self):\n",
    "        for i in range(1, self.recurrences+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, c, o = self.LSTM.forwardProp()\n",
    "            #store cell state from the forward propagation\n",
    "            self.ca[i] = cs #cell state\n",
    "            self.ha[i] = hs #hidden state\n",
    "            self.af[i] = f #forget state\n",
    "            self.ai[i] = inp #inpute gate\n",
    "            self.ac[i] = c #cell state\n",
    "            self.ao[i] = o #output gate\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs)) #activate the weight*input\n",
    "            self.x = self.expected_output[i-1]\n",
    "        return self.oa\n",
    "   \n",
    "    # Back propagation\n",
    "    def backProp(self):\n",
    "        totalError = 0\n",
    "        #cell state\n",
    "        dfcs = np.zeros(self.output)\n",
    "        #hidden state,\n",
    "        dfhs = np.zeros(self.output)\n",
    "        #weight matrix\n",
    "        tu = np.zeros((self.output,self.output))\n",
    "        #forget gate\n",
    "        tfu = np.zeros((self.output, self.input+self.output))\n",
    "        #input gate\n",
    "        tiu = np.zeros((self.output, self.input+self.output))\n",
    "        #cell unit\n",
    "        tcu = np.zeros((self.output, self.input+self.output))\n",
    "        #output gate\n",
    "        tou = np.zeros((self.output, self.input+self.output))\n",
    "        for i in range(self.recurrences, -1, -1):\n",
    "            error = self.oa[i] - self.expected_output[i]\n",
    "            tu += np.dot(np.atleast_2d(error * self.dsigmoid(self.oa[i])), np.atleast_2d(self.ha[i]).T)\n",
    "            error = np.dot(error, self.w)\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.ia[i]))\n",
    "            self.LSTM.cs = self.ca[i]\n",
    "            fu, iu, cu, ou, dfcs, dfhs = self.LSTM.backProp(error, self.ca[i-1], self.af[i], self.ai[i], self.ac[i], self.ao[i], dfcs, dfhs)\n",
    "            totalError += np.sum(error)\n",
    "            #forget gate\n",
    "            tfu += fu\n",
    "            #input gate\n",
    "            tiu += iu\n",
    "            #cell state\n",
    "            tcu += cu\n",
    "            #output gate\n",
    "            tou += ou   \n",
    "        self.LSTM.update(tfu/self.recurrences, tiu/self.recurrences, tcu/self.recurrences, tou/self.recurrences)  \n",
    "        self.update(tu/self.recurrences)\n",
    "        return totalError\n",
    "    \n",
    "    def update(self, u):\n",
    "        self.G = 0.95 * self.G + 0.1 * u**2  \n",
    "        self.w -= self.learning_rate/np.sqrt(self.G + 1e-8) * u\n",
    "        return\n",
    "    \n",
    "    def sample(self):\n",
    "        for i in range(1, self.recurrences+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n",
    "            maxI = np.argmax(self.x)\n",
    "            self.x = np.zeros_like(self.x)\n",
    "            self.x[maxI] = 1\n",
    "            self.ia[i] = self.x \n",
    "            #store cell states\n",
    "            self.ca[i] = cs\n",
    "            #store hidden state\n",
    "            self.ha[i] = hs\n",
    "            #forget gate\n",
    "            self.af[i] = f\n",
    "            #input gate\n",
    "            self.ai[i] = inp\n",
    "            #cell state\n",
    "            self.ac[i] = c\n",
    "            #output gate\n",
    "            self.ao[i] = o\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            maxI = np.argmax(self.oa[i])\n",
    "            newX = np.zeros_like(self.x)\n",
    "            newX[maxI] = 1\n",
    "            self.x = newX\n",
    "           \n",
    "        return self.oa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long short-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    # LSTM cell (input, output, amount of recurrence, learning rate)\n",
    "    def __init__ (self, input, output, recurrences, learning_rate):\n",
    "        #input size\n",
    "        self.x = np.zeros(input+output)\n",
    "        #input size\n",
    "        self.input = input + output\n",
    "        #output \n",
    "        self.y = np.zeros(output)\n",
    "        #output size\n",
    "        self.output = output\n",
    "        #cell state intialized as size of prediction\n",
    "        self.cs = np.zeros(output)\n",
    "        #how often to perform recurrence\n",
    "        self.recurrences = recurrences\n",
    "        #balance the rate of training (learning rate)\n",
    "        self.learning_rate = learning_rate\n",
    "        #init weight matrices for our gates\n",
    "        #forget gate\n",
    "        self.f = np.random.random((output, input+output))\n",
    "        #input gate\n",
    "        self.i = np.random.random((output, input+output))\n",
    "        #cell state\n",
    "        self.c = np.random.random((output, input+output))\n",
    "        #output gate\n",
    "        self.o = np.random.random((output, input+output))\n",
    "        #forget gate gradient\n",
    "        self.Gf = np.zeros_like(self.f)\n",
    "        #input gate gradient\n",
    "        self.Gi = np.zeros_like(self.i)\n",
    "        #cell state gradient\n",
    "        self.Gc = np.zeros_like(self.c)\n",
    "        #output gate gradient\n",
    "        self.Go = np.zeros_like(self.o)\n",
    "    \n",
    "   \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    \n",
    "    def tangent(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    \n",
    "    def dtangent(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "  \n",
    "    def forwardProp(self):\n",
    "        f = self.sigmoid(np.dot(self.f, self.x))\n",
    "        self.cs *= f\n",
    "        i = self.sigmoid(np.dot(self.i, self.x))\n",
    "        c = self.tangent(np.dot(self.c, self.x))\n",
    "        self.cs += i * c\n",
    "        o = self.sigmoid(np.dot(self.o, self.x))\n",
    "        self.y = o * self.tangent(self.cs)\n",
    "        return self.cs, self.y, f, i, c, o\n",
    "    \n",
    "   \n",
    "    def backProp(self, e, pcs, f, i, c, o, dfcs, dfhs):\n",
    "        \n",
    "        e = np.clip(e + dfhs, -6, 6)\n",
    "        \n",
    "        do = self.tangent(self.cs) * e\n",
    "        \n",
    "        ou = np.dot(np.atleast_2d(do * self.dtangent(o)).T, np.atleast_2d(self.x))\n",
    "        \n",
    "        dcs = np.clip(e * o * self.dtangent(self.cs) + dfcs, -6, 6)\n",
    "        \n",
    "        dc = dcs * i\n",
    "    \n",
    "        cu = np.dot(np.atleast_2d(dc * self.dtangent(c)).T, np.atleast_2d(self.x))\n",
    "      \n",
    "        di = dcs * c\n",
    "        \n",
    "        iu = np.dot(np.atleast_2d(di * self.dsigmoid(i)).T, np.atleast_2d(self.x))\n",
    "       \n",
    "        df = dcs * pcs\n",
    "        \n",
    "        fu = np.dot(np.atleast_2d(df * self.dsigmoid(f)).T, np.atleast_2d(self.x))\n",
    "       \n",
    "        dpcs = dcs * f\n",
    "        \n",
    "        dphs = np.dot(dc, self.c)[:self.output] + np.dot(do, self.o)[:self.output] + np.dot(di, self.i)[:self.output] + np.dot(df, self.f)[:self.output] \n",
    "       \n",
    "        return fu, iu, cu, ou, dpcs, dphs\n",
    "            \n",
    "    def update(self, fu, iu, cu, ou):\n",
    "        #Update forget, input, cell, and output gradients\n",
    "        self.Gf = 0.9 * self.Gf + 0.1 * fu**2 \n",
    "        self.Gi = 0.9 * self.Gi + 0.1 * iu**2   \n",
    "        self.Gc = 0.9 * self.Gc + 0.1 * cu**2   \n",
    "        self.Go = 0.9 * self.Go + 0.1 * ou**2   \n",
    "        \n",
    "        #Update our gates using our gradients\n",
    "        self.f -= self.learning_rate/np.sqrt(self.Gf + 1e-8) * fu\n",
    "        self.i -= self.learning_rate/np.sqrt(self.Gi + 1e-8) * iu\n",
    "        self.c -= self.learning_rate/np.sqrt(self.Gc + 1e-8) * cu\n",
    "        self.o -= self.learning_rate/np.sqrt(self.Go + 1e-8) * ou\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
